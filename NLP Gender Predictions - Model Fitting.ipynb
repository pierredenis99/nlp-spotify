{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing libraries and creating model score functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report,recall_score,precision_score,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import functions from spotify_functions.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotify_functions import model_score,nn_model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import dataset of clean lyrics and gender target variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.read_csv('csv_to_predict.csv')\n",
    "\n",
    "df_predict = df_predict.iloc[:,1:]\n",
    "\n",
    "df_predict.drop('lyrics',axis=1,inplace=True)\n",
    "\n",
    "df_predict.columns = ['gender','lyrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenize and split data into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_predict['lyrics']\n",
    "y = list(df_predict['gender'])\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tk = Tokenizer(\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{\"}~\\t\\n',\n",
    "               lower=True,\n",
    "               char_level=False,\n",
    "               split=' ')\n",
    "tk.fit_on_texts(x)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Understand our features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredenis/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaahhhhh</th>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaherra</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aamu</th>\n",
       "      <th>aandt</th>\n",
       "      <th>aao</th>\n",
       "      <th>...</th>\n",
       "      <th>zoomin</th>\n",
       "      <th>zoot</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zot</th>\n",
       "      <th>zotnyzor</th>\n",
       "      <th>zoyd</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zumschloss</th>\n",
       "      <th>zyngarettes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371 rows × 25700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaaaahhhhh  aaaahhhhh  aaah  aah  aaherra  aaliyah  aamu  aandt  \\\n",
       "0     0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "1     0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "2     0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "3     0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "4     0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "...   ...         ...        ...   ...  ...      ...      ...   ...    ...   \n",
       "1366  0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "1367  0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "1368  0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "1369  0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "1370  0.0         0.0        0.0   0.0  0.0      0.0      0.0   0.0    0.0   \n",
       "\n",
       "      aao  ...  zoomin  zoot  zorro  zot  zotnyzor  zoyd  zulu  zuma  \\\n",
       "0     0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "1     0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "2     0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "3     0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "4     0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "...   ...  ...     ...   ...    ...  ...       ...   ...   ...   ...   \n",
       "1366  0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "1367  0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "1368  0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "1369  0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "1370  0.0  ...     0.0   0.0    0.0  0.0       0.0   0.0   0.0   0.0   \n",
       "\n",
       "      zumschloss  zyngarettes  \n",
       "0            0.0          0.0  \n",
       "1            0.0          0.0  \n",
       "2            0.0          0.0  \n",
       "3            0.0          0.0  \n",
       "4            0.0          0.0  \n",
       "...          ...          ...  \n",
       "1366         0.0          0.0  \n",
       "1367         0.0          0.0  \n",
       "1368         0.0          0.0  \n",
       "1369         0.0          0.0  \n",
       "1370         0.0          0.0  \n",
       "\n",
       "[1371 rows x 25700 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf_wm = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "tfidf_tokens = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "df_countvect = pd.DataFrame(data=tfidf_wm.toarray(),columns = tfidf_tokens)\n",
    "\n",
    "df_countvect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vectorizing with Count Vectorizer and TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "c_vectorizer = CountVectorizer()\n",
    "X_train_vect_c = c_vectorizer.fit_transform(X_train)\n",
    "X_test_vect_c = c_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "t_vectorizer = TfidfVectorizer()\n",
    "X_train_vect_t = t_vectorizer.fit_transform(X_train)\n",
    "X_test_vect_t = t_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Count vectorizer + Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.5536105032822757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       207\n",
      "           1       0.59      0.62      0.60       250\n",
      "\n",
      "    accuracy                           0.55       457\n",
      "   macro avg       0.55      0.55      0.55       457\n",
      "weighted avg       0.55      0.55      0.55       457\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Women</th>\n",
       "      <th>Predicted Men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Women</th>\n",
       "      <td>97</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Men</th>\n",
       "      <td>94</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Women  Predicted Men\n",
       "Actual Women               97            110\n",
       "Actual Men                 94            156"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report,recall_score,precision_score,accuracy_score\n",
    "\n",
    "dt_count = DecisionTreeClassifier()\n",
    "dt_count.fit(X_train_vect_c,y_train)\n",
    "\n",
    "\n",
    "model_score(dt_count,X_test_vect_c,X_train_vect_c,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: Severe case of overfitting when using the base decision tree algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Count vectorizer + Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.6367614879649891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.41      0.51       207\n",
      "           1       0.63      0.82      0.71       250\n",
      "\n",
      "    accuracy                           0.64       457\n",
      "   macro avg       0.64      0.62      0.61       457\n",
      "weighted avg       0.64      0.64      0.62       457\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Women</th>\n",
       "      <th>Predicted Men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Women</th>\n",
       "      <td>85</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Men</th>\n",
       "      <td>44</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Women  Predicted Men\n",
       "Actual Women               85            122\n",
       "Actual Men                 44            206"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_count = RandomForestClassifier()\n",
    "rf_count.fit(X_train_vect_c,y_train)\n",
    "\n",
    "model_score(rf_count,X_test_vect_c,X_train_vect_c,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: We are dealing with another severe case of overfititng when using the basic random forest algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TFIDF Vectorizer + Tuned Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.6236323851203501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.43      0.51       207\n",
      "           1       0.62      0.79      0.70       250\n",
      "\n",
      "    accuracy                           0.62       457\n",
      "   macro avg       0.62      0.61      0.60       457\n",
      "weighted avg       0.62      0.62      0.61       457\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Women</th>\n",
       "      <th>Predicted Men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Women</th>\n",
       "      <td>88</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Men</th>\n",
       "      <td>53</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Women  Predicted Men\n",
       "Actual Women               88            119\n",
       "Actual Men                 53            197"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "rf_tfidf = RandomForestClassifier()\n",
    "rf_tfidf.fit(X_train_vect_t,y_train)\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [2,3,8],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : [1,5,10],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "rf_tuned = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=cv,verbose=0)\n",
    "rf_tuned.fit(X_train_vect_t, y_train)\n",
    "\n",
    "model_score(rf_tfidf,X_test_vect_t,X_train_vect_t,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TFIDF + Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8358862144420132\n",
      "Test Accuracy: 0.6083150984682714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.44      0.51       207\n",
      "           1       0.62      0.74      0.68       250\n",
      "\n",
      "    accuracy                           0.61       457\n",
      "   macro avg       0.60      0.59      0.59       457\n",
      "weighted avg       0.61      0.61      0.60       457\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Women</th>\n",
       "      <th>Predicted Men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Women</th>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Men</th>\n",
       "      <td>64</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Women  Predicted Men\n",
       "Actual Women               92            115\n",
       "Actual Men                 64            186"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train_vect_t, y_train)\n",
    "\n",
    "model_score(logisticRegr,X_test_vect_t,X_train_vect_t,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TFIDF + Logistic Regression Tuned**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(max_iter=500),\n",
       "             param_grid={&#x27;C&#x27;: [0.5, 1, 1.2, 1.5, 2, 5], &#x27;penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(max_iter=500),\n",
       "             param_grid={&#x27;C&#x27;: [0.5, 1, 1.2, 1.5, 2, 5], &#x27;penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=500),\n",
       "             param_grid={'C': [0.5, 1, 1.2, 1.5, 2, 5], 'penalty': ['l2']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_values = {'penalty': ['l2'], 'C': [0.5,1,1.2,1.5,2,5]}\n",
    "lr_tuned = GridSearchCV(LogisticRegression(solver='lbfgs',max_iter=500), param_grid=grid_values,refit=True,verbose=1)\n",
    "lr_tuned.fit(X_train_vect_t,y_train)\n",
    "\n",
    "# We've increased the number of iterations because the solver wouldn't converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8358862144420132\n",
      "Test Accuracy: 0.6083150984682714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.44      0.51       207\n",
      "           1       0.62      0.74      0.68       250\n",
      "\n",
      "    accuracy                           0.61       457\n",
      "   macro avg       0.60      0.59      0.59       457\n",
      "weighted avg       0.61      0.61      0.60       457\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Women</th>\n",
       "      <th>Predicted Men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Women</th>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Men</th>\n",
       "      <td>64</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Women  Predicted Men\n",
       "Actual Women               92            115\n",
       "Actual Men                 64            186"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score(lr_tuned,X_test_vect_t,X_train_vect_t,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TFIDF + SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7950401167031363\n",
      "Test Accuracy: 0.5448577680525164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       207\n",
      "           1       0.55      1.00      0.71       250\n",
      "\n",
      "    accuracy                           0.54       457\n",
      "   macro avg       0.27      0.50      0.35       457\n",
      "weighted avg       0.30      0.54      0.39       457\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Women</th>\n",
       "      <th>Predicted Men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Women</th>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Men</th>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Women  Predicted Men\n",
       "Actual Women                0            207\n",
       "Actual Men                  1            249"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_tfidf = make_pipeline(StandardScaler(with_mean=False),SVC(gamma='auto'))\n",
    "svm_tfidf.fit(X_train_vect_t,y_train)\n",
    "\n",
    "model_score(svm_tfidf,X_test_vect_t,X_train_vect_t,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: The SVM severely overpredicts men in its predictions, as shown by the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TFIDF + SVM tuned**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "svm_tuned = GridSearchCV(SVC(),param_grid,refit=True,verbose=1)\n",
    "svm_tuned.fit(X_train_vect_t,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8796498905908097\n",
      "Test Accuracy: 0.6280087527352297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56       207\n",
      "           1       0.65      0.71      0.68       250\n",
      "\n",
      "    accuracy                           0.63       457\n",
      "   macro avg       0.62      0.62      0.62       457\n",
      "weighted avg       0.63      0.63      0.63       457\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Women</th>\n",
       "      <th>Predicted Men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Women</th>\n",
       "      <td>110</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Men</th>\n",
       "      <td>73</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Women  Predicted Men\n",
       "Actual Women              110             97\n",
       "Actual Men                 73            177"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score(svm_tuned,X_test_vect_t,X_train_vect_t,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cross validation - 5 folds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "models = [dt_count,rf_count,rf_tfidf,svm_tfidf,svm_tuned,rf_tuned]\n",
    "\n",
    "\n",
    "score=['accuracy','f1','precision','recall']\n",
    "\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "prec_list = []\n",
    "rec_list = []\n",
    "\n",
    "\n",
    "vect = CountVectorizer()\n",
    "\n",
    "x_vect = vect.fit_transform(x)\n",
    "\n",
    "for model in models:\n",
    "    res = cross_validate(model,x_vect,y,scoring = score,cv=5)\n",
    "    acc = (res['test_accuracy'].mean())\n",
    "    f1 = (res['test_f1'].mean())\n",
    "    prec =(res['test_precision'].mean())\n",
    "    rec =(res['test_recall'].mean())\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.547041</td>\n",
       "      <td>0.590875</td>\n",
       "      <td>0.579646</td>\n",
       "      <td>0.603228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.603924</td>\n",
       "      <td>0.670275</td>\n",
       "      <td>0.609606</td>\n",
       "      <td>0.746221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.609376</td>\n",
       "      <td>0.677567</td>\n",
       "      <td>0.613583</td>\n",
       "      <td>0.757261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(StandardScaler(with_mean=False), SVC(gamma='a...</td>\n",
       "      <td>0.544309</td>\n",
       "      <td>0.704505</td>\n",
       "      <td>0.543813</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GridSearchCV(estimator=SVC(),\\n             pa...</td>\n",
       "      <td>0.538820</td>\n",
       "      <td>0.586962</td>\n",
       "      <td>0.565466</td>\n",
       "      <td>0.628369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GridSearchCV(cv=LeaveOneOut(),\\n             e...</td>\n",
       "      <td>0.551399</td>\n",
       "      <td>0.647490</td>\n",
       "      <td>0.565353</td>\n",
       "      <td>0.764474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Models  Accuracy        F1  \\\n",
       "0                           DecisionTreeClassifier()  0.547041  0.590875   \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', r...  0.603924  0.670275   \n",
       "2  (DecisionTreeClassifier(max_features='sqrt', r...  0.609376  0.677567   \n",
       "3  (StandardScaler(with_mean=False), SVC(gamma='a...  0.544309  0.704505   \n",
       "4  GridSearchCV(estimator=SVC(),\\n             pa...  0.538820  0.586962   \n",
       "5  GridSearchCV(cv=LeaveOneOut(),\\n             e...  0.551399  0.647490   \n",
       "\n",
       "   Precision    Recall  \n",
       "0   0.579646  0.603228  \n",
       "1   0.609606  0.746221  \n",
       "2   0.613583  0.757261  \n",
       "3   0.543813  1.000000  \n",
       "4   0.565466  0.628369  \n",
       "5   0.565353  0.764474  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=['accuracy','f1','precision','recall']\n",
    "\n",
    "\n",
    "cross_val_df = pd.DataFrame({'Models': models,'Accuracy':acc_list,'F1':f1_list,'Precision':prec_list,'Recall':rec_list})\n",
    "\n",
    "cross_val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The following table helps us clear any misinterpretation regarding the randomization effect of our dataset splitting. As we can see, all our models seem to predict poorly when using cross validation, even though we had some models generating better results on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a Stemmed Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stemmed = df_predict.copy()\n",
    "\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "df_stemmed['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in df_stemmed['lyrics']] \n",
    "\n",
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "# Get the stemmed_tokens\n",
    "df_stemmed['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df_stemmed['tokenized_text'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['when', 'your', 'legs', \"don't\", 'work', 'lik...</td>\n",
       "      <td>[when, your, legs, don, work, like, they, used...</td>\n",
       "      <td>['when', 'your', 'leg', 'don', 'work', 'like',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[\"i'm\", 'gonna', 'pick', 'up', 'the', 'pieces'...</td>\n",
       "      <td>[gonna, pick, up, the, pieces, and, build, leg...</td>\n",
       "      <td>['gonna', 'pick', 'up', 'the', 'piec', 'and', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['white', 'lips,', 'pale', 'face', 'breathing'...</td>\n",
       "      <td>[white, lips, pale, face, breathing, in, the, ...</td>\n",
       "      <td>['white', 'lip', 'pale', 'face', 'breath', 'in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'was', 'so', 'high', 'i', 'did', 'not', ...</td>\n",
       "      <td>[was, so, high, did, not, recognize, the, fire...</td>\n",
       "      <td>['wa', 'so', 'high', 'did', 'not', 'recogn', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['may', 'i', 'have', 'your', 'attention,', 'pl...</td>\n",
       "      <td>[may, have, your, attention, please, may, have...</td>\n",
       "      <td>['mai', 'have', 'your', 'attent', 'pleas', 'ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>0</td>\n",
       "      <td>['common', 'love', \"isn't\", 'for', 'us', 'we',...</td>\n",
       "      <td>[common, love, isn, for, us, we, created, some...</td>\n",
       "      <td>['common', 'love', 'isn', 'for', 'us', 'we', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>0</td>\n",
       "      <td>['i', \"didn't\", 'ask', 'for', 'a', 'free', 'ri...</td>\n",
       "      <td>[didn, ask, for, free, ride, only, asked, you,...</td>\n",
       "      <td>['didn', 'ask', 'for', 'free', 'ride', 'onli',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>0</td>\n",
       "      <td>['day', 'to', 'night', 'to', 'morning,', 'keep...</td>\n",
       "      <td>[day, to, night, to, morning, keep, with, me, ...</td>\n",
       "      <td>['dai', 'to', 'night', 'to', 'morn', 'keep', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>0</td>\n",
       "      <td>['maybe', \"it's\", 'the', 'way', 'you', 'say', ...</td>\n",
       "      <td>[maybe, it, the, way, you, say, my, name, mayb...</td>\n",
       "      <td>['mayb', 'it', 'the', 'wai', 'you', 'sai', 'my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>0</td>\n",
       "      <td>['ooh-ooh-ooh', 'ah-ah-ah-ah-ah', 'brown', 'gu...</td>\n",
       "      <td>[ooh, ooh, ooh, ah, ah, ah, ah, ah, brown, gui...</td>\n",
       "      <td>['ooh', 'ooh', 'ooh', 'ah', 'ah', 'ah', 'ah', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1828 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender                                             lyrics  \\\n",
       "0          1  ['when', 'your', 'legs', \"don't\", 'work', 'lik...   \n",
       "1          1  [\"i'm\", 'gonna', 'pick', 'up', 'the', 'pieces'...   \n",
       "2          1  ['white', 'lips,', 'pale', 'face', 'breathing'...   \n",
       "3          1  ['i', 'was', 'so', 'high', 'i', 'did', 'not', ...   \n",
       "4          1  ['may', 'i', 'have', 'your', 'attention,', 'pl...   \n",
       "...      ...                                                ...   \n",
       "1823       0  ['common', 'love', \"isn't\", 'for', 'us', 'we',...   \n",
       "1824       0  ['i', \"didn't\", 'ask', 'for', 'a', 'free', 'ri...   \n",
       "1825       0  ['day', 'to', 'night', 'to', 'morning,', 'keep...   \n",
       "1826       0  ['maybe', \"it's\", 'the', 'way', 'you', 'say', ...   \n",
       "1827       0  ['ooh-ooh-ooh', 'ah-ah-ah-ah-ah', 'brown', 'gu...   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "0     [when, your, legs, don, work, like, they, used...   \n",
       "1     [gonna, pick, up, the, pieces, and, build, leg...   \n",
       "2     [white, lips, pale, face, breathing, in, the, ...   \n",
       "3     [was, so, high, did, not, recognize, the, fire...   \n",
       "4     [may, have, your, attention, please, may, have...   \n",
       "...                                                 ...   \n",
       "1823  [common, love, isn, for, us, we, created, some...   \n",
       "1824  [didn, ask, for, free, ride, only, asked, you,...   \n",
       "1825  [day, to, night, to, morning, keep, with, me, ...   \n",
       "1826  [maybe, it, the, way, you, say, my, name, mayb...   \n",
       "1827  [ooh, ooh, ooh, ah, ah, ah, ah, ah, brown, gui...   \n",
       "\n",
       "                                         stemmed_tokens  \n",
       "0     ['when', 'your', 'leg', 'don', 'work', 'like',...  \n",
       "1     ['gonna', 'pick', 'up', 'the', 'piec', 'and', ...  \n",
       "2     ['white', 'lip', 'pale', 'face', 'breath', 'in...  \n",
       "3     ['wa', 'so', 'high', 'did', 'not', 'recogn', '...  \n",
       "4     ['mai', 'have', 'your', 'attent', 'pleas', 'ma...  \n",
       "...                                                 ...  \n",
       "1823  ['common', 'love', 'isn', 'for', 'us', 'we', '...  \n",
       "1824  ['didn', 'ask', 'for', 'free', 'ride', 'onli',...  \n",
       "1825  ['dai', 'to', 'night', 'to', 'morn', 'keep', '...  \n",
       "1826  ['mayb', 'it', 'the', 'wai', 'you', 'sai', 'my...  \n",
       "1827  ['ooh', 'ooh', 'ooh', 'ah', 'ah', 'ah', 'ah', ...  \n",
       "\n",
       "[1828 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stemmed['stemmed_tokens'] = df_stemmed['stemmed_tokens'].astype(str)\n",
    "df_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stem = df_stemmed['stemmed_tokens']\n",
    "y_stem = list(df_stemmed['gender'])\n",
    "X_train_stem,X_test_stem,y_train_stem,y_test_stem = train_test_split(x_stem,y_stem,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stemmed Dataset + TFIDF + SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Train Accuracy: 0.8701677607585704\n",
      "Test Accuracy: 0.6389496717724289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58       207\n",
      "           1       0.66      0.71      0.68       250\n",
      "\n",
      "    accuracy                           0.64       457\n",
      "   macro avg       0.63      0.63      0.63       457\n",
      "weighted avg       0.64      0.64      0.64       457\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Women</th>\n",
       "      <th>Predicted Men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Women</th>\n",
       "      <td>114</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Men</th>\n",
       "      <td>72</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted Women  Predicted Men\n",
       "Actual Women              114             93\n",
       "Actual Men                 72            178"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect_s = vectorizer.fit_transform(X_train_stem)\n",
    "X_test_vect_s = vectorizer.transform(X_test_stem)\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "svm_tuned_s = GridSearchCV(SVC(),param_grid,refit=True,verbose=1)\n",
    "svm_tuned_s.fit(X_train_vect_s,y_train)\n",
    "\n",
    "model_score(svm_tuned_s,X_test_vect_s,X_train_vect_s,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: The stemmed dataset doesn't seem to have an impact on the predictive power of our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TFIDF + Sequential Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_score(model,x_test,x_train,y_test,y_train):\n",
    "    print('Train Results:')\n",
    "    print(model.evaluate(x_train,np.asarray(y_train)))\n",
    "    print('Test Results:')\n",
    "    print(model.evaluate(x_test,np.asarray(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredenis/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "2023-01-09 17:19:38.116009: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e058820>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_1 = tf.keras.Sequential(tf.keras.layers.Dense(1))\n",
    "\n",
    "model_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "\n",
    "                    optimizer = tf.keras.optimizers.SGD(),\n",
    "\n",
    "                    metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "train_y_nump = np.asarray(y_train)\n",
    "\n",
    "\n",
    "model_1.fit(X_train_vect_t,train_y_nump,epochs = 200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results:\n",
      "43/43 [==============================] - 0s 655us/step - loss: 0.4842 - accuracy: 0.7980\n",
      "[0.48423969745635986, 0.797957718372345]\n",
      "Test Results:\n",
      "15/15 [==============================] - 0s 756us/step - loss: 0.6581 - accuracy: 0.6105\n",
      "[0.6581444144248962, 0.6105032563209534]\n"
     ]
    }
   ],
   "source": [
    "nn_model_score(model_1,X_test_vect_t,X_train_vect_t,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Neural Network - Model 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredenis/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_1/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_1/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_1/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e12dd880>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(40)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "\n",
    "  tf.keras.layers.Dense(100), # add 100 dense neurons\n",
    "\n",
    "  tf.keras.layers.Dense(10), # add another layer with 10 neurons\n",
    "\n",
    "  tf.keras.layers.Dense(1)\n",
    "\n",
    "])\n",
    "\n",
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "\n",
    "                optimizer=tf.keras.optimizers.Adam(), \n",
    "\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(X_train_vect_t,train_y_nump, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results:\n",
      "43/43 [==============================] - 0s 960us/step - loss: 0.0338 - accuracy: 0.9978\n",
      "[0.033752623945474625, 0.9978117942810059]\n",
      "Test Results:\n",
      "15/15 [==============================] - 0s 921us/step - loss: 4.5220 - accuracy: 0.5930\n",
      "[4.522022724151611, 0.5929977893829346]\n"
     ]
    }
   ],
   "source": [
    "nn_model_score(model_2,X_test_vect_t,X_train_vect_t,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Neural Network - Model 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredenis/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/pierredenis/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape:0\", shape=(None, 10), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e228a430>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = tf.keras.Sequential([\n",
    "\n",
    "                               tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "\n",
    "                               tf.keras.layers.Dense(4, activation = 'relu'),\n",
    "\n",
    "                               tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "\n",
    "])\n",
    "\n",
    "model_3.compile( loss= tf.keras.losses.binary_crossentropy,\n",
    "\n",
    "                optimizer = tf.keras.optimizers.Adam(lr = 0.01),\n",
    "\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model_3.fit(X_train_vect_t, train_y_nump, epochs = 25, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results:\n",
      "43/43 [==============================] - 0s 704us/step - loss: 0.0996 - accuracy: 0.9759\n",
      "[0.0996043011546135, 0.9759299755096436]\n",
      "Test Results:\n",
      "15/15 [==============================] - 0s 705us/step - loss: 1.6594 - accuracy: 0.6302\n",
      "[1.6593981981277466, 0.6301969289779663]\n"
     ]
    }
   ],
   "source": [
    "nn_model_score(model_3,X_test_vect_t,X_train_vect_t,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**: \n",
    "In conclusion, most of our models had severe cases of overfitting. When trying to tune the parameters to reduce the overfitting, the models weren't able to generalise well on the validation set. In fact, our results seem to indicate that the lyrics aren't a strong predictor to assess the gender of an artist. This could be the case for many reason, such as the fact that most songs often contains sounds rather than words. Furthermore, the lyrics of songs released in the more recent years often contain less lyrics, making it harder for our algorithm to generate a robust prediction. \n",
    "\n",
    "To further our analysis, we could try to analyse the emotions contained in the lyrics of a song, and create a predictive model in such a way that the prediction is based off the emotions of the lyrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6784ea8354c1a4e92dd4a3a4f9c136644445949effe8e7f8d40a791ec0f6e5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
